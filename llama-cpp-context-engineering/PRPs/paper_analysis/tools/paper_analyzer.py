#!/usr/bin/env python3
"""
æ¨ç†ä¼˜åŒ–è®ºæ–‡åˆ†æå·¥å…·å¥—ä»¶
åŸºäºContext Engineeringæ–¹æ³•è®ºï¼Œç³»ç»Ÿæ€§åˆ†æè®ºæ–‡çš„å®æ–½å¯è¡Œæ€§å’Œä¼˜å…ˆçº§
"""

import json
import re
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple, Optional
from enum import Enum
from datetime import datetime

class TechCategory(Enum):
    QUANTIZATION = "é‡åŒ–æŠ€æœ¯"
    ATTENTION = "æ³¨æ„åŠ›ä¼˜åŒ–"
    KV_CACHE = "KVç¼“å­˜ä¼˜åŒ–"
    SPECULATIVE = "æ¨æµ‹é‡‡æ ·"
    KERNEL_FUSION = "ç®—å­èåˆ"
    HETEROGENEOUS = "å¼‚æ„æ¨ç†"
    SAMPLING = "é‡‡æ ·ä¼˜åŒ–"
    SPARSITY = "ç¨€ç–åŒ–"
    INFERENCE_SCALING = "æ¨ç†æ—¶æ‰©å±•"

class Difficulty(Enum):
    LOW = 1      # 1-2å‘¨å®ç°
    MEDIUM = 2   # 1-2æœˆå®ç°
    HIGH = 3     # 3-6æœˆå®ç°
    EXPERT = 4   # 6æœˆ+æˆ–éœ€è¦ä¸“å®¶

class Impact(Enum):
    LOW = 1      # <10% æ€§èƒ½æå‡
    MEDIUM = 2   # 10-30% æ€§èƒ½æå‡  
    HIGH = 3     # 30-60% æ€§èƒ½æå‡
    CRITICAL = 4 # >60% æ€§èƒ½æå‡

@dataclass
class Paper:
    title: str
    url: str
    category: TechCategory
    difficulty: Difficulty
    impact: Impact
    llama_compatibility: float  # 0-1, ä¸llama.cppç°æœ‰æ¶æ„çš„å…¼å®¹æ€§
    description: str
    key_techniques: List[str]
    dependencies: List[str]
    risks: List[str]
    estimated_weeks: int

class PaperAnalyzer:
    """è®ºæ–‡åˆ†æå’Œä¼˜å…ˆçº§è¯„ä¼°å·¥å…·"""
    
    def __init__(self):
        self.papers = []
        self.load_papers()
    
    def load_papers(self):
        """ä»è®ºæ–‡åˆ—è¡¨ä¸­åŠ è½½å¹¶åˆ†ç±»åˆ†æ"""
        
        # åŸºäºè®ºæ–‡å†…å®¹è¿›è¡Œåˆ†ç±»å’Œè¯„ä¼°
        papers_data = [
            # é‡åŒ–æŠ€æœ¯ç±»
            {
                "title": "ABQ-LLM: Arbitrary-Bit Quantization for Large Language Models", 
                "url": "éœ€è¦è¡¥å……",
                "category": TechCategory.QUANTIZATION,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.HIGH,
                "llama_compatibility": 0.7,
                "description": "ä»»æ„ä½é‡åŒ–æŠ€æœ¯ï¼Œå¯å®ç°W4A4ç­‰æä½ç²¾åº¦é‡åŒ–",
                "key_techniques": ["arbitrary-bité‡åŒ–", "gradient-basedä¼˜åŒ–", "æ··åˆç²¾åº¦æ¨ç†"],
                "dependencies": ["CUDA kernelå¼€å‘", "é‡åŒ–æ¡†æ¶é‡æ„"],
                "risks": ["ç²¾åº¦æŸå¤±é£é™©", "å¤æ‚çš„æ ¡å‡†è¿‡ç¨‹"],
                "estimated_weeks": 16
            },
            {
                "title": "FlatQuant: Flatness Matters for LLM Quantization",
                "url": "https://arxiv.org/html/2410.09426v1",
                "category": TechCategory.QUANTIZATION,
                "difficulty": Difficulty.MEDIUM,
                "impact": Impact.MEDIUM,
                "llama_compatibility": 0.8,
                "description": "åŸºäºå¹³å¦åº¦çš„W4A4é‡åŒ–æ–¹æ³•ï¼Œæå‡é‡åŒ–ç²¾åº¦",
                "key_techniques": ["flatness-awareé‡åŒ–", "æƒé‡ä¼˜åŒ–"],
                "dependencies": ["ç°æœ‰é‡åŒ–æ¡†æ¶"],
                "risks": ["è®¡ç®—å¼€é”€å¢åŠ "],
                "estimated_weeks": 8
            },
            
            # Attentionä¼˜åŒ–ç±»
            {
                "title": "INT-FlashAttention: Enabling Flash Attention for INT8 Quantization",
                "url": "https://arxiv.org/html/2409.16997v1", 
                "category": TechCategory.ATTENTION,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.CRITICAL,
                "llama_compatibility": 0.9,
                "description": "INT8é‡åŒ–çš„FlashAttentionå®ç°ï¼Œå¤§å¹…é™ä½æ˜¾å­˜ä½¿ç”¨",
                "key_techniques": ["INT8 attentionè®¡ç®—", "memory-efficientå®ç°"],
                "dependencies": ["ç°æœ‰FlashAttentioné›†æˆ", "CUDA INT8 kernels"],
                "risks": ["æ•°å€¼ç²¾åº¦é—®é¢˜", "ç¡¬ä»¶å…¼å®¹æ€§"],
                "estimated_weeks": 12
            },
            {
                "title": "SageAttention: Accurate 8-bit attention for Plug-and-Play Inference Acceleration", 
                "url": "https://arxiv.org/html/2410.02367v1",
                "category": TechCategory.ATTENTION,
                "difficulty": Difficulty.MEDIUM,
                "impact": Impact.HIGH,
                "llama_compatibility": 0.8,
                "description": "å³æ’å³ç”¨çš„8-bit attentionåŠ é€Ÿæ–¹æ¡ˆ",
                "key_techniques": ["8-bit attention", "ç²¾åº¦è¡¥å¿ç®—æ³•"],
                "dependencies": ["attention kernelé‡å†™"],
                "risks": ["æ¨¡å‹ç²¾åº¦å½±å“"],
                "estimated_weeks": 10
            },
            
            # KV Cacheä¼˜åŒ–ç±»
            {
                "title": "KV-Compress: Paged KV-Cache Compression",
                "url": "https://arxiv.org/html/2410.00161v2",
                "category": TechCategory.KV_CACHE,
                "difficulty": Difficulty.MEDIUM,
                "impact": Impact.HIGH, 
                "llama_compatibility": 0.7,
                "description": "åˆ†é¡µå¼KVç¼“å­˜å‹ç¼©ï¼Œä¸åŒattention headä½¿ç”¨ä¸åŒå‹ç¼©ç‡",
                "key_techniques": ["åˆ†é¡µå‹ç¼©", "å¯å˜å‹ç¼©ç‡", "attention headåˆ†æ"],
                "dependencies": ["KVç¼“å­˜ç³»ç»Ÿé‡æ„"],
                "risks": ["å®ç°å¤æ‚åº¦é«˜", "è°ƒä¼˜å›°éš¾"],
                "estimated_weeks": 14
            },
            {
                "title": "KV Cache is 1 Bit Per Channel",
                "url": "https://arxiv.org/abs/2405.03917",
                "category": TechCategory.KV_CACHE,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.CRITICAL,
                "llama_compatibility": 0.6,
                "description": "æè‡´çš„1-bit KVç¼“å­˜å‹ç¼©æŠ€æœ¯",
                "key_techniques": ["1-bité‡åŒ–", "è€¦åˆé‡åŒ–", "é‡æ„ç®—æ³•"],
                "dependencies": ["å…¨æ–°KVç¼“å­˜æ¶æ„"],
                "risks": ["ç²¾åº¦å¤§å¹…ä¸‹é™é£é™©", "æ¶æ„æ”¹åŠ¨å·¨å¤§"],
                "estimated_weeks": 20
            },
            
            # æ¨æµ‹é‡‡æ ·ç±»
            {
                "title": "Eagle3 Speculative Sampling",
                "url": "éœ€è¦è¡¥å……",
                "category": TechCategory.SPECULATIVE,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.HIGH,
                "llama_compatibility": 0.6,
                "description": "Eagle3æ¨æµ‹è§£ç ç®—æ³•ï¼Œæå‡æ¨ç†ååé‡",
                "key_techniques": ["å¤šçº§æ¨æµ‹", "åŠ¨æ€è°ƒæ•´", "å¹¶è¡Œç”Ÿæˆ"],
                "dependencies": ["æ¨æµ‹è§£ç æ¡†æ¶"],
                "risks": ["å¤æ‚çš„è°ƒåº¦é€»è¾‘", "å†…å­˜å¼€é”€å¢åŠ "],
                "estimated_weeks": 18
            },
            {
                "title": "QSpec Quantization-aware Speculative Decoding",
                "url": "https://arxiv.org/html/2410.11305v1",
                "category": TechCategory.SPECULATIVE,
                "difficulty": Difficulty.EXPERT,
                "impact": Impact.HIGH,
                "llama_compatibility": 0.5,
                "description": "é‡åŒ–æ„ŸçŸ¥çš„æ¨æµ‹è§£ç ï¼Œç»“åˆé‡åŒ–å’Œæ¨æµ‹é‡‡æ ·",
                "key_techniques": ["é‡åŒ–æ¨æµ‹", "è‡ªé€‚åº”é˜ˆå€¼", "æ¨¡å‹è’¸é¦"],
                "dependencies": ["é‡åŒ–æ¡†æ¶", "æ¨æµ‹è§£ç æ¡†æ¶"],
                "risks": ["æŠ€æœ¯å¤æ‚åº¦æé«˜", "è°ƒä¼˜å›°éš¾"],
                "estimated_weeks": 24
            },
            
            # ç®—å­èåˆç±»
            {
                "title": "AWQç®—å­èåˆæŠ€æœ¯",
                "url": "éœ€è¦è¡¥å……",
                "category": TechCategory.KERNEL_FUSION,
                "difficulty": Difficulty.MEDIUM,
                "impact": Impact.MEDIUM,
                "llama_compatibility": 0.8,
                "description": "å‚è€ƒAutoAWQçš„ç®—å­èåˆç­–ç•¥ï¼Œå‡å°‘kernelè°ƒç”¨å¼€é”€",
                "key_techniques": ["dequantèåˆ", "GEMMèåˆ", "activationèåˆ"],
                "dependencies": ["ç°æœ‰CUDA kernels"],
                "risks": ["kernelå¤æ‚åº¦å¢åŠ "],
                "estimated_weeks": 10
            },
            
            # å¼‚æ„æ¨ç†ç±»  
            {
                "title": "KTransformerså¼‚æ„æ¨ç†ç‰¹æ€§",
                "url": "https://www.bilibili.com/video/BV1VNQrYGEad/",
                "category": TechCategory.HETEROGENEOUS,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.MEDIUM,
                "llama_compatibility": 0.6,
                "description": "CPU-GPUå¼‚æ„æ¨ç†ï¼ŒåŸºäºå†…å­˜çš„æˆæœ¬ä¼˜åŒ–",
                "key_techniques": ["å¼‚æ„è°ƒåº¦", "å†…å­˜ä¼˜åŒ–", "è®¡ç®—åˆ†å‘"],
                "dependencies": ["æ¶æ„é‡å¤§æ”¹åŠ¨"],
                "risks": ["å…¼å®¹æ€§é—®é¢˜", "è°ƒåº¦å¤æ‚"],
                "estimated_weeks": 20
            },
            
            # é‡‡æ ·ä¼˜åŒ–ç±»
            {
                "title": "Sorting-Free GPU Kernels for LLM Sampling",
                "url": "https://flashinfer.ai/2025/03/10/sampling.html",
                "category": TechCategory.SAMPLING,
                "difficulty": Difficulty.MEDIUM,
                "impact": Impact.MEDIUM,
                "llama_compatibility": 0.9,
                "description": "æ— æ’åºçš„GPUé‡‡æ ·kernelsï¼Œæå‡é‡‡æ ·æ•ˆç‡",
                "key_techniques": ["æ— æ’åºé‡‡æ ·", "å¹¶è¡ŒåŒ–ä¼˜åŒ–", "å†…å­˜è®¿é—®ä¼˜åŒ–"],
                "dependencies": ["ç°æœ‰é‡‡æ ·æ¡†æ¶"],
                "risks": ["æ•°å€¼ç¨³å®šæ€§"],
                "estimated_weeks": 6
            },
            
            # ç¨€ç–åŒ–ç±»
            {
                "title": "Training-Free Activation Sparsity in Large Language Models",
                "url": "https://arxiv.org/html/2408.14690v1",
                "category": TechCategory.SPARSITY,
                "difficulty": Difficulty.HIGH,
                "impact": Impact.HIGH,
                "llama_compatibility": 0.7,
                "description": "å…è®­ç»ƒçš„æ¿€æ´»ç¨€ç–åŒ–æŠ€æœ¯",
                "key_techniques": ["æ¿€æ´»ç¨€ç–åŒ–", "åŠ¨æ€pruning", "å…è®­ç»ƒä¼˜åŒ–"],
                "dependencies": ["ç¨€ç–è®¡ç®—æ¡†æ¶"],
                "risks": ["ç²¾åº¦æŸå¤±", "åŠ¨æ€æ€§èƒ½å¼€é”€"],
                "estimated_weeks": 16
            }
        ]
        
        for data in papers_data:
            paper = Paper(**data)
            self.papers.append(paper)
    
    def calculate_priority_score(self, paper: Paper) -> float:
        """è®¡ç®—ä¼˜å…ˆçº§å¾—åˆ† = (å½±å“åŠ› * å…¼å®¹æ€§) / éš¾åº¦"""
        impact_score = paper.impact.value
        compatibility_score = paper.llama_compatibility
        difficulty_penalty = paper.difficulty.value
        
        return (impact_score * compatibility_score * 10) / difficulty_penalty
    
    def generate_priority_matrix(self) -> List[Tuple[Paper, float]]:
        """ç”Ÿæˆä¼˜å…ˆçº§çŸ©é˜µ"""
        scored_papers = []
        for paper in self.papers:
            score = self.calculate_priority_score(paper)
            scored_papers.append((paper, score))
        
        # æŒ‰å¾—åˆ†é™åºæ’åº
        scored_papers.sort(key=lambda x: x[1], reverse=True)
        return scored_papers
    
    def categorize_by_timeframe(self) -> Dict[str, List[Paper]]:
        """æŒ‰å®æ–½æ—¶é—´æ¡†æ¶åˆ†ç±»"""
        timeframes = {
            "çŸ­æœŸ (1-2æœˆ)": [],
            "ä¸­æœŸ (3-6æœˆ)": [], 
            "é•¿æœŸ (6æœˆ+)": []
        }
        
        for paper in self.papers:
            if paper.estimated_weeks <= 8:
                timeframes["çŸ­æœŸ (1-2æœˆ)"].append(paper)
            elif paper.estimated_weeks <= 24:
                timeframes["ä¸­æœŸ (3-6æœˆ)"].append(paper)
            else:
                timeframes["é•¿æœŸ (6æœˆ+)"].append(paper)
                
        return timeframes
    
    def generate_risk_assessment(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆé£é™©è¯„ä¼°æŠ¥å‘Š"""
        risk_categories = {
            "æŠ€æœ¯é£é™©": [],
            "å…¼å®¹æ€§é£é™©": [],
            "æ€§èƒ½é£é™©": [],
            "ç»´æŠ¤é£é™©": []
        }
        
        for paper in self.papers:
            for risk in paper.risks:
                if "ç²¾åº¦" in risk or "æ•°å€¼" in risk:
                    risk_categories["æ€§èƒ½é£é™©"].append(f"{paper.title}: {risk}")
                elif "å…¼å®¹" in risk or "æ¶æ„" in risk:
                    risk_categories["å…¼å®¹æ€§é£é™©"].append(f"{paper.title}: {risk}")
                elif "å¤æ‚" in risk or "å›°éš¾" in risk:
                    risk_categories["æŠ€æœ¯é£é™©"].append(f"{paper.title}: {risk}")
                else:
                    risk_categories["ç»´æŠ¤é£é™©"].append(f"{paper.title}: {risk}")
                    
        return risk_categories
    
    def export_analysis_results(self, output_path: str):
        """å¯¼å‡ºåˆ†æç»“æœåˆ°JSON"""
        results = {
            "analysis_timestamp": datetime.now().isoformat(),
            "total_papers": len(self.papers),
            "papers": [asdict(paper) for paper in self.papers],
            "priority_matrix": [(asdict(paper), score) for paper, score in self.generate_priority_matrix()],
            "timeframe_categories": {k: [asdict(p) for p in v] for k, v in self.categorize_by_timeframe().items()},
            "risk_assessment": self.generate_risk_assessment()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)

def main():
    print("ğŸš€ å¯åŠ¨æ¨ç†ä¼˜åŒ–è®ºæ–‡åˆ†æ")
    print("åŸºäºContext Engineeringæ–¹æ³•è®ºçš„ç³»ç»Ÿæ€§åˆ†æ")
    print("="*60)
    
    analyzer = PaperAnalyzer()
    
    # ç”Ÿæˆä¼˜å…ˆçº§æ’åº
    priority_list = analyzer.generate_priority_matrix()
    
    print("\nğŸ“Š ä¼˜å…ˆçº§æ’åº (å‰10å):")
    for i, (paper, score) in enumerate(priority_list[:10], 1):
        print(f"{i:2d}. {paper.title[:50]:<50} å¾—åˆ†: {score:.2f}")
        print(f"    åˆ†ç±»: {paper.category.value}, éš¾åº¦: {paper.difficulty.name}, å½±å“: {paper.impact.name}")
        print(f"    å…¼å®¹æ€§: {paper.llama_compatibility:.1f}, é¢„è®¡: {paper.estimated_weeks}å‘¨")
        print()
    
    # å¯¼å‡ºå®Œæ•´åˆ†æç»“æœ
    analyzer.export_analysis_results("/root/llama.cpp-clip/PRPs/paper_analysis/results/paper_analysis_results.json")
    
    print("âœ… åˆ†æå®Œæˆï¼è¯¦ç»†ç»“æœå·²å¯¼å‡ºåˆ° paper_analysis_results.json")

if __name__ == "__main__":
    main()